{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read raw data\n",
      "write command file\n",
      "Job 1\n",
      "Job 2\n",
      "Job 3\n",
      "Job 4\n",
      "Job 5\n",
      "Job 6\n",
      "Job 7\n",
      "Job 8\n",
      "Job 9\n",
      "Job 10\n",
      "Job 11\n",
      "Job 12\n",
      "Job 13\n",
      "Job 14\n",
      "Job 15\n",
      "Job 16\n",
      "Job 17\n",
      "Job 18\n",
      "Job 19\n",
      "Job 20\n",
      "Job 21\n",
      "Job 22\n",
      "Job 23\n",
      "Job 24\n",
      "Job 25\n",
      "Job 26\n",
      "Job 27\n",
      "Job 28\n",
      "Job 29\n",
      "Job 30\n",
      "Job 31\n",
      "Job 32\n",
      "Job 33\n",
      "Job 34\n",
      "Job 35\n",
      "Job 36\n",
      "Job 37\n",
      "Job 38\n",
      "Job 39\n",
      "Job 40\n",
      "Job 41\n",
      "Job 42\n",
      "Job 43\n",
      "Job 44\n",
      "Job 45\n",
      "Job 46\n",
      "Job 47\n",
      "Job 48\n",
      "Job 49\n",
      "Job 50\n",
      "Job 51\n",
      "Job 52\n",
      "Job 53\n",
      "Job 54\n",
      "Job 55\n",
      "Job 56\n",
      "Job 57\n",
      "Job 58\n",
      "Job 59\n",
      "Job 60\n",
      "Job 61\n",
      "Job 62\n",
      "Job 63\n",
      "Job 64\n",
      "Job 65\n",
      "Job 66\n",
      "Job 67\n",
      "Job 68\n",
      "Job 69\n",
      "Job 70\n",
      "Job 71\n",
      "Job 72\n",
      "Job 73\n",
      "Job 74\n",
      "Job 75\n",
      "Job 76\n",
      "Job 77\n",
      "Job 78\n",
      "Job 79\n",
      "Job 80\n",
      "Job 81\n",
      "Job 82\n",
      "Job 83\n",
      "Job 84\n",
      "Job 85\n",
      "Job 86\n",
      "Job 87\n",
      "Job 88\n",
      "Total job number = 88\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from osgeo import gdal\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "gdal.UseExceptions()\n",
    "\n",
    "# This script is to create and submit mulctiple Sx calculations\n",
    "\n",
    "work_dir='/glade/u/home/hongli/scratch/2020_11_29discretization_error/discretize/yampa'\n",
    "script_dir='/glade/u/home/hongli/github/2020_11_29discretization_error/radiation_wind_functions'\n",
    "script_file='step5_raw_Sx_function.py'\n",
    "\n",
    "row_interval=70 # use 38BG memory\n",
    "col_interval=70\n",
    "buf_grid_window=100 #130, 300 # unit:m\n",
    "dem_nodata=-9999\n",
    "\n",
    "# =======================input and output =============================\n",
    "dem_raster=os.path.join(work_dir, 'dem_crop.tif')\n",
    "dem_buf_raster=os.path.join(work_dir, 'dem_crop_buf.tif') # extend for dem raster Sx\n",
    "opath=os.path.join(work_dir, 'step5_raw_Sx')\n",
    "if not os.path.exists(opath):\n",
    "    os.makedirs(opath)\n",
    "command_folder=os.path.join(work_dir, 'step5_raw_Sx_command')\n",
    "if os.path.exists(command_folder):\n",
    "    shutil.rmtree(command_folder) \n",
    "os.makedirs(command_folder)\n",
    "shutil.copyfile(os.path.join(script_dir, script_file), os.path.join(command_folder,script_file))\n",
    " \n",
    "#====================================================\n",
    "# read raw raster [ELEVATION]\n",
    "print('read raw data')\n",
    "r = gdal.Open(dem_raster)\n",
    "band = r.GetRasterBand(1) #bands start at one\n",
    "elev = band.ReadAsArray().astype(np.float)\n",
    "mask = (elev==dem_nodata)\n",
    "(ny,nx)=np.shape(elev)\n",
    "\n",
    "print('write command file')\n",
    "os.chdir(command_folder)\n",
    "\n",
    "if ny%row_interval==0:\n",
    "    row_job_num=ny//row_interval\n",
    "else:\n",
    "    row_job_num=ny//row_interval+1\n",
    "if nx%col_interval==0:\n",
    "    col_job_num=nx//col_interval\n",
    "else:\n",
    "    col_job_num=nx//col_interval+1 \n",
    "\n",
    "job_id = 0 \n",
    "for i in range(row_job_num):\n",
    "    for j in range(col_job_num):\n",
    "\n",
    "        row_start = i*row_interval\n",
    "        col_start = j*col_interval\n",
    "        if (ny%row_interval!=0) and (i==row_job_num-1):\n",
    "            row_end=row_start+ny%row_interval\n",
    "        else:\n",
    "            row_end = (i+1)*row_interval\n",
    "        if (nx%col_interval!=0) and (j==col_job_num-1):\n",
    "            col_end = col_start+nx%col_interval\n",
    "        else:\n",
    "            col_end = (j+1)*col_interval\n",
    "            \n",
    "        mask_subset = mask[row_start:row_end,col_start:col_end]\n",
    "        if not mask_subset.all()==True:        \n",
    "            job_id = job_id+1\n",
    "            print('Job '+str(job_id))\n",
    "            \n",
    "            # create command file\n",
    "            command_file='qsub_Job'+str(job_id)+'_Row'+str(row_start)+'_'+str(row_end)\\\n",
    "            +'_Col'+str(col_start)+'_'+str(col_end)+'.sh'\n",
    "            command_file_path = os.path.join(command_folder,command_file)\n",
    "            if os.path.exists(command_file_path):\n",
    "                os.remove(command_file_path)\n",
    "                \n",
    "            with open(command_file_path,'w') as f:\n",
    "                f.write('#!/bin/bash\\n')\n",
    "                f.write('#PBS -N SxJob'+str(job_id)+'\\n')\n",
    "                f.write('#PBS -A P48500028\\n')\n",
    "                f.write('#PBS -q regular\\n')\n",
    "                f.write('#PBS -l walltime=00:25:00\\n')\n",
    "                f.write('#PBS -l select=1:ncpus=1:mpiprocs=1\\n') \n",
    "                f.write('#PBS -j oe\\n\\n')\n",
    "                f.write('export TMPDIR=/glade/scratch/hongli/tmp\\n')\n",
    "                f.write('mkdir -p $TMPDIR\\n\\n')                \n",
    "                f.write('module load peak_memusage\\n\\n') # monitor peak memory usage   \n",
    "                # Note: cheyenne usable memory per compute node is 45GB.\n",
    "                f.write('peak_memusage.exe /glade/u/home/hongli/tools/miniconda3/envs/conda_hongli/bin/python '\\\n",
    "                        +os.path.join(command_folder,script_file)+' '+dem_raster+' '+dem_buf_raster+' '\\\n",
    "                        +str(row_start)+' '+str(row_end)+' '\\\n",
    "                        +str(col_start)+' '+str(col_end)+' '\\\n",
    "                        +str(buf_grid_window)+' '+opath)\n",
    "                \n",
    "            # submit job\n",
    "            os.system('chmod 740 '+command_file)\n",
    "            os.system('qsub '+command_file)\n",
    "\n",
    "os.chdir(work_dir)        \n",
    "print('Total job number = '+str(job_id))\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "import matplotlib.pyplot as plt \n",
    "dem_origin_file ='/glade/u/home/hongli/scratch/2020_11_29discretization_error/discretize/source_data/MERIT_Hydro_dem_NLDAS.tif'\n",
    "\n",
    "with rio.open(dem_origin_file) as ff:\n",
    "    in_raster_value  = ff.read(1)\n",
    "    in_raster_mask = ff.read_masks(1)\n",
    "    gt = ff.transform\n",
    "\n",
    "dx = gt[0]\n",
    "dy = -gt[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0008333333333333467, 0.0008333333333333467)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx,dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_hongli",
   "language": "python",
   "name": "conda_hongli"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
